

<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>A Collection of Literature on Probabilistic Graphical Models</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Dong" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">A Collection of Literature on Probabilistic Graphical Models</h1>
<p>
<b>The collection of literature work on Probabilistic Graphical Models (PGMs). Source file can be found at git repository <a href="https://github.com/FirstHandScientist/pgm_map">pgm-map</a>.</b>
</p>

<div id="outline-container-orgff93f4a" class="outline-2">
<h2 id="orgff93f4a"><span class="section-number-2">1</span> Book and Monograph on PGMs</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org7770da0" class="outline-3">
<h3 id="org7770da0"><span class="section-number-3">1.1</span> Books / Monograph:</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>Kingma and Welling, 2019, <a href="https://arxiv.org/abs/1906.02691">An Introduction to Variational Autoencoders</a></li>
<li>Sutton, 2010, <a href="https://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf">An Introduction to Conditional Random Fields</a></li>
<li>Wainwright, 2008, <a href="file:///home/dong/Documents/my_eBooks/mLearning/graphical_models_wainwright.pdf">Graphical Models, Exponential Families, and Variational Inference</a></li>
<li>Koller, 2009, <a href="file:///home/dong/Documents/my_eBooks/mLearning/probabilistic_graphical_models_principles_techniques.pdf">Probabilistic graphical models: principles and techniques</a></li>
<li>Mark Rowland, 2018, <a href="https://www.repository.cam.ac.uk/handle/1810/287479">Structure in Machine Learning: Graphical Models and Monte Carlo Methods</a></li>
<li>Yingzhen Li, 2018, <a href="https://www.repository.cam.ac.uk/handle/1810/277549">Approximate Inference: New Visions</a></li>
<li>Adrian Weller, 2014, <a href="http://mlg.eng.cam.ac.uk/adrian/phd_FINAL.pdf">Methods for Inference in Graphical Models</a></li>
</ul>

<ul class="org-ul">
<li>Angelino, et al 2016, <a href="https://www.nowpublishers.com/article/Details/MAL-052">Patterns of Scalable Bayesian Inference</a></li>
<li>Komodakis etc, 2016, <a href="https://www.nowpublishers.com/article/Details/CGV-066">(Hyper)-Graphs Inference through Convex Relaxations and Move Making Algorithms: Contributions and Applications in Artificial Vision</a></li>
<li>Bogdan Savchynskyy, 2019, <a href="file:///home/dong/Documents/my_eBooks/mLearning/discrete_graphical_models_an_optimization_perspective.pdf">Discrete Graphical Models &#x2013; An Optimization Perspective</a></li>
<li>Angelino, 2016, <a href="https://www.nowpublishers.com/article/Details/MAL-052">Patterns of Scalable Bayesian Inference</a></li>
<li><p>
Nowozin, 2011, <a href="http://www.nowozin.net/sebastian/papers/nowozin2011structured-tutorial.pdf">Structured Learning and Prediction in Computer Vision</a>
</p>

<p>
Ihler, Alexander:
</p></li>

<li>Lou, Qi, 2018, <a href="https://escholarship.org/uc/item/7sc0m97f">Anytime Approximate Inference in Graphical Models</a></li>
<li>Ping, Wei, 2016, <a href="https://escholarship.org/uc/item/7q90z4b5">Learning and Inference in Latent Variable Graphical Models</a></li>
<li>Forouzan, Sholeh, 2015, <a href="https://escholarship.org/uc/item/5n4733cz">Approximate Inference in Graphical Models</a></li>
<li><p>
Qiang, Liu, 2014, <a href="https://escholarship.org/uc/item/92p8w3xb">Reasoning and Decisions in Probabilistic Graphical Models - A Unified Framework</a>
</p>

<p>
Minka:
</p></li>

<li>Yuan Qi, 2005, <a href="https://affect.media.mit.edu/pdfs/05.qi-phd.pdf">Extending Expectation Propagation for Graphical Models</a></li>
<li>Thomas P Minka, 2001, <a href="https://tminka.github.io/papers/ep/minka-thesis.pdf">A family of algorithms for approximate Bayesian inference</a></li>
</ul>
</div>
</div>
</div>



<div id="outline-container-org78094cc" class="outline-2">
<h2 id="org78094cc"><span class="section-number-2">2</span> Inference and Learning of PGMs Papers</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org35b3f91" class="outline-3">
<h3 id="org35b3f91"><span class="section-number-3">2.1</span> Inference methods and techniques</h3>
<div class="outline-text-3" id="text-2-1">
</div>
<div id="outline-container-org4ab6a9b" class="outline-4">
<h4 id="org4ab6a9b"><span class="section-number-4">2.1.1</span> Classical Inference Methods</h4>
<div class="outline-text-4" id="text-2-1-1">
<ul class="org-ul">
<li>Lee et al, 2019, EMP, <a href="https://arxiv.org/abs/1907.01127">Convergence rates of smooth message passing with rounding in entropy-regularized MAP inference</a></li>
<li>Fletcher, 2017, <a href="https://arxiv.org/abs/1602.07795">Expectation Consistent Approximate Inference: Generalizations and Convergence</a></li>
<li>Convergence Analysis, Roosta, 2008, <a href="https://ieeexplore.ieee.org/document/4599175">Convergence Analysis of Reweighted Sum-Product Algorithms</a></li>
<li>Generalized BP for marginal distributions, Yedidis, et al, 2005, <a href="https://www.cs.princeton.edu/courses/archive/spring06/cos598C/papers/YedidaFreemanWeiss2004.pdf">Constructing free energy approximations and Generalized belief propagation algorithms</a></li>
<li>Tree-structured EP, Minka and Qi, <a href="https://tminka.github.io/papers/eptree/minka-eptree.pdf">Tree-structured approximations by expectation propagation</a></li>
<li>Winn &amp; Bishop, 2005, <a href="http://www.jmlr.org/papers/volume6/winn05a/winn05a.pdf">Variational message passing</a></li>
<li>Opper, Winther, 2005, <a href="http://www.jmlr.org/papers/volume6/opper05a/opper05a.pdf">Expectation Consistent Approximate Inference</a></li>
<li>Wainwright et al, 2003, <a href="http://ssg.mit.edu/group/willsky/publ_pdfs/166_pub_AISTATS.pdf">tree-reweighted belief propagation algorithms and approximated ML esimation by pseudo-moment matching</a></li>
<li>Wainwright and Willsky, 2003, <a href="https://papers.nips.cc/paper/2206-exact-map-estimates-by-hypertree-agreement.pdf">Exact MAP estimates by hypertree agreement</a></li>
<li>Tourani et al, 2018, <a href="https://hci.iwr.uni-heidelberg.de/vislearn/HTML/people/bogdan/publications/papers/tourani-mplp-plus-plus-eccv2018.pdf">MPLP++: Fast, Parallel Dual Block-Coordinate Ascent for Dense Graphical Models</a></li>
<li>Haller et al, 2018, <a href="https://arxiv.org/abs/2004.06370">Exact MAP-Inference by Confining Combinatorial Search with LP Relaxation</a></li>
<li>Globerson, Jaakkola, 2008, <a href="https://papers.nips.cc/paper/3200-fixing-max-product-convergent-message-passing-algorithms-for-map-lp-relaxations.pdf">Fixing Max-Product: Convergent Message PassingAlgorithms for MAP LP-Relaxations</a></li>
</ul>
</div>
</div>

<div id="outline-container-org78264d9" class="outline-4">
<h4 id="org78264d9"><span class="section-number-4">2.1.2</span> Improvements</h4>
<div class="outline-text-4" id="text-2-1-2">
<ul class="org-ul">
<li>Conditioning, Clamping, Divide

<ul class="org-ul">
<li>Zhou et al, 2020, <a href="https://arxiv.org/abs/1910.13324">Divide, Conquer, and Combine: a New Inference Strategy for Probabilistic Programs with Stochastic Support</a></li>
<li>Eaton and Ghahramani, 2009, <a href="http://mlg.eng.cam.ac.uk/pub/pdf/EatGha09.pdf">Choosing a Variable to Clamp</a></li>
<li>Geier et al, 2015, <a href="http://auai.org/uai2015/proceedings/papers/158.pdf">Locally Conditioned Belief Propagation</a></li>
<li>Weller and Jebara, 2014, <a href="https://papers.nips.cc/paper/5529-clamping-variables-and-approximate-inference.pdf">Clamping Variables and Approximate Inference</a></li>
</ul></li>
</ul>


<ul class="org-ul">
<li>Linear Response. Welling and Teh, <a href="https://www.ics.uci.edu/~welling/publications/papers/LR2.pdf">Linear Response Algorithms for Approximate Inference in Graphical Models</a></li>

<li>Combining with Particle/Stochastic Methods

<ul class="org-ul">
<li>Liu et al, 2015, <a href="https://papers.nips.cc/paper/5695-probabilistic-variational-bounds-for-graphical-models">Probabilistic Variational Bounds for Graphical Models</a></li>
<li>Noorshams and Wainwright, 2013, <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6373728">stochastic belief propagation: a low-complexity alternative to the sum-product algorithm</a></li>
<li>Lienart, et al, Expectation Particle Belief Propagation</li>
<li>Ihler, McAllester, 2009, <a href="http://proceedings.mlr.press/v5/ihler09a/ihler09a.pdf">Particle Belief Propagation</a></li>
</ul></li>

<li>Mixture/multi-modal
<ul class="org-ul">
<li>Baque et al, 2017, <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Baque_Multi-Modal_Mean-Fields_via_CVPR_2017_paper.pdf">Multi-Modal Mean-Fields via Cardinality-Based Clamping</a></li>
<li>Hao Xiong et al, 2019, <a href="http://auai.org/uai2019/proceedings/papers/19.pdf">One-Shot Marginal MAP Inference in Markov Random Fields</a></li>
</ul></li>

<li>Layered messages
<ul class="org-ul">
<li>Jampani et al, 2015, <a href="http://proceedings.mlr.press/v38/jampani15.pdf">Consensus Message Passing for Layered Graphical Models</a></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org9788b2f" class="outline-4">
<h4 id="org9788b2f"><span class="section-number-4">2.1.3</span> Application</h4>
<div class="outline-text-4" id="text-2-1-3">
<ul class="org-ul">
<li><a href="https://papers.nips.cc/paper/9532-combining-generative-and-discriminative-models-for-hybrid-inference.pdf">Satorras, 2019, Combining Generative and Discriminative Models for Hybrid Inference</a></li>
<li><a href="https://arxiv.org/pdf/1502.03240.pdf">Zheng, 2019, Conditional Random Fields as Recurrent Neural Networks</a></li>
<li><a href="https://arxiv.org/abs/1210.5644">Krahenbuhl, 2011, Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials</a></li>
</ul>
</div>
</div>



<div id="outline-container-org49d001e" class="outline-4">
<h4 id="org49d001e"><span class="section-number-4">2.1.4</span> Variational methods</h4>
<div class="outline-text-4" id="text-2-1-4">
<ul class="org-ul">
<li>NIPS tutorial 2016, <a href="https://media.nips.cc/Conferences/2016/Slides/6199-Slides.pdf">Variational Inference</a></li>
<li>Kingma and Welling, 2014, Autoencoder: <a href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes</a></li>
<li>Kuleshov and Ermon, 2017, NVIL: <a href="https://arxiv.org/abs/1711.02679">Neural Variational Inference and Learning in Undirected Graphical Models</a></li>
<li>Li, etc, 2020, AdVIL: <a href="https://arxiv.org/abs/1901.08400">To Relieve Your Headache of Training an MRF, Take AdVIL</a></li>
<li>Lazaro-Gredilla, 2019 (Vicarious AI), <a href="https://arxiv.org/abs/1912.02893">Learning undirected models via query training</a></li>
<li>Sobolev and Vetrov, 2019, (Section 3 gives interesting discussion on literature works) <a href="http://papers.nips.cc/paper/8350-importance-weighted-hierarchical-variational-inference">Importance Weighted Hierarchical Variational Inference</a></li>
<li>Kingma, et al, 2016, <a href="https://papers.nips.cc/paper/6581-improved-variational-inference-with-inverse-autoregressive-flow">Improved Variational Inference with Inverse Autoregressive Flow</a></li>
<li>Rezende, Mohamed, 2015, <a href="https://arxiv.org/abs/1505.05770">Variational Inference with Normalizing Flows</a></li>

<li>Domke, 2019, <a href="https://arxiv.org/abs/1901.08431">Provable Smoothness Guarantees for Black-Box Variational Inference</a></li>
<li>Blei, 2017, <a href="https://amstat.tandfonline.com/doi/pdf/10.1080/01621459.2017.1285773?needAccess=true">Variational Inference: A Review for Statisticians</a></li>
<li>Regier et al, 2017, <a href="https://papers.nips.cc/paper/6834-fast-black-box-variational-inference-through-stochastic-trust-region-optimization.pdf">Fast Black-box Variational Inferencethrough Stochastic Trust-Region Optimization</a></li>
<li>Kucukelbir et al, 2016, <a href="https://arxiv.org/pdf/1603.00788.pdf">Automatic differentiation variational inference</a></li>
<li>Black-box alpha, 2016, <a href="http://proceedings.mlr.press/v48/hernandez-lobatob16.pdf">Black-box alpha-divergence minimization</a></li>
<li>Ranganath et al, 2014, <a href="http://proceedings.mlr.press/v33/ranganath14.pdf">Black box variational inference</a></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org8c583b9" class="outline-3">
<h3 id="org8c583b9"><span class="section-number-3">2.2</span> Neural network based methods</h3>
<div class="outline-text-3" id="text-2-2">
</div>
<div id="outline-container-org731b817" class="outline-4">
<h4 id="org731b817"><span class="section-number-4">2.2.1</span> Deep learning based methods</h4>
<div class="outline-text-4" id="text-2-2-1">
<ul class="org-ul">
<li>Stoller et al, 2020, <a href="https://arxiv.org/pdf/1905.12660.pdf">Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators</a></li>
<li>Karaletsos, 2016, <a href="https://arxiv.org/abs/1612.05048">Adversarial Message Passing For Graphical Models</a></li>
</ul>

<p>
Learning messages
</p>

<ul class="org-ul">
<li>Heess et al, <a href="https://papers.nips.cc/paper/5070-learning-to-pass-expectation-propagation-messages.pdf">Learning to Pass Expectation Propagation Messages</a>, half-automated message passing, message-level automation</li>
<li>Yoon et al, 2018, <a href="https://arxiv.org/abs/1803.07710">Inference in Probabilistic Graphical Models by Graph Neural Networks</a></li>
<li>Lin, 2015, <a href="http://papers.nips.cc/paper/5791-deeply-learning-the-messages-in-message-passing-inference.pdf">Deeply Learning the Messages in Message Passing Inference</a></li>
</ul>

<p>
Graphical Neural Networks
</p>

<ul class="org-ul">
<li><a href="https://arxiv.org/abs/1905.06214">GMNN: Graph Markov Neural Networks</a>, semi-supervised learning, EM is used for training.</li>
<li>More generalized computation power: <a href="https://github.com/deepmind/graph_nets">Graph Net Library</a>, A graph network takes a graph as input and returns a graph as output.</li>
<li>Related, <a href="https://github.com/dmlc/dgl">Deep Graph Library</a>, for deep learning on graphs</li>
<li>Scarselli et al, 2009, <a href="https://persagen.com/files/misc/scarselli2009graph.pdf">The graph neural network model</a></li>
<li>Satorras and Welling, 2020, <a href="https://arxiv.org/abs/2003.01998">Neural Enhanced Belief Propagation on Factor Graphs</a></li>
</ul>
</div>
</div>


<div id="outline-container-org611dcb0" class="outline-4">
<h4 id="org611dcb0"><span class="section-number-4">2.2.2</span> Neural density function estimation</h4>
<div class="outline-text-4" id="text-2-2-2">
<ul class="org-ul">
<li>Chen et al, 2018, ODE: <a href="https://papers.nips.cc/paper/7892-neural-ordinary-differential-equations">Neural Ordinary Differential Equations</a></li>
<li>Kingma, Dhariwal, 2018, <a href="https://arxiv.org/abs/1807.03039">Glow: Generative Flow with Invertible 1x1 Convolutions</a></li>
<li>Dinh, Sohl-Dickstein, Bengio, 2017, <a href="https://arxiv.org/pdf/1605.08803.pdf">Density Estimation using Real NVP</a></li>
<li>Dinh, Krueger, Bengio, 2014, <a href="https://arxiv.org/abs/1410.8516">NICE: Non-linear independent component estimation</a></li>
<li>Inverse autoregreeeive flow as in previous subsection.</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org89c463a" class="outline-3">
<h3 id="org89c463a"><span class="section-number-3">2.3</span> Learning of Graphical Models</h3>
<div class="outline-text-3" id="text-2-3">
</div>
<div id="outline-container-orgdc97ae4" class="outline-4">
<h4 id="orgdc97ae4"><span class="section-number-4">2.3.1</span> Parameter Learning</h4>
<div class="outline-text-4" id="text-2-3-1">
<p>
Learning graphical model parameters by approximate inference
</p>

<ul class="org-ul">
<li>Domke, 2013, <a href="https://ieeexplore.ieee.org/abstract/document/6420841">Learning Graphical Model Parameters with Approximate Marginal Inference</a></li>
<li>Tang, 2015, <a href="https://arxiv.org/abs/1503.01228">Bethe Learning of Conditional Random Fields via MAP Decoding</a></li>
<li>You Lu, 2019, <a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/4357">Block Belief Propagation for Parameter Learning in Markov Random Fields</a></li>
<li>Hazan, 2016, <a href="http://www.jmlr.org/papers/v17/13-260.html">Blending Learning and Inference in Conditional Random Fields</a></li>
</ul>

<p>
Learning of MRF with neural networks
</p>

<ul class="org-ul">
<li>Wiseman and Kim, 2019, <a href="https://papers.nips.cc/paper/9687-amortized-bethe-free-energy-minimization-for-learning-mrfs.pdf">Amortized Bethe Free Energy Minimization for Learning MRFs</a></li>
<li>Kuleshov and Ermon, 2017, <a href="https://arxiv.org/abs/1711.02679">Neural Variational Inference and Learning in Undirected Graphical Models</a></li>
</ul>

<p>
Learning of Directed Graphs
</p>

<ul class="org-ul">
<li>Chongxuan Li, 2020, <a href="https://arxiv.org/abs/1901.08400">To Relieve Your Headache of Training an MRF, Take AdVIL</a></li>
<li>Mnih and Gregor, 2014, <a href="https://arxiv.org/abs/1402.0030">Neural Variational Inference and Learning in Belief Networks</a></li>
<li>NIPS tutorial 2016, <a href="https://media.nips.cc/Conferences/2016/Slides/6199-Slides.pdf">Variational Inference</a></li>
</ul>
</div>
</div>
</div>
</div>


<div id="outline-container-org416d131" class="outline-2">
<h2 id="org416d131"><span class="section-number-2">3</span> PGM and Decision-making in Dynamic Systems</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li>Sutton, Barto, 2018, <a href="https://github.com/FirstHandScientist/Reinforcement-Learning-2nd-Edition-by-Sutton-Exercise-Solutions">Reinforcement learning (2ed edition)</a></li>

<li>Martin L. Puterman, 2014, Markov Decision Processes: Discrete Stochastic Dynamic Programming</li>

<li>Francois-Lavet, et al 2018, <a href="https://arxiv.org/abs/1811.12560">An Introduction to Deep Reinforcement Learning</a></li>

<li>Bubeck, Cesa-Bianchi, 2012, <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/01/SurveyBCB12.pdf">Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems</a></li>

<li>Ziebart, 2010, <a href="https://www.cs.cmu.edu/~bziebart/publications/thesis-bziebart.pdf">Modeling Purposeful Adaptive Behavior with the Principle of Maximum Causal Entropy</a></li>

<li>Levin, 2018, <a href="https://arxiv.org/abs/1805.00909">Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review</a></li>

<li>Haarnoja, et al 2017, <a href="https://arxiv.org/pdf/1702.08165.pdf">Reinforcement Learning with Deep Energy-Based Policies</a></li>

<li>Szepesvari, 2009, <a href="https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs-lecture.pdf">Algorithms for Reinforcement Learning</a></li>
</ul>
</div>


<div id="outline-container-org10b28b1" class="outline-3">
<h3 id="org10b28b1"><span class="section-number-3">3.1</span> Courses</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li><a href="https://www.davidsilver.uk/teaching/">Reinforcement Learning (UCL)</a></li>
<li><a href="http://rail.eecs.berkeley.edu/deeprlcourse/">Deep Reinforcement Learning (CS285)</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs">Advanced Deep Learning &amp; Reinforcement Learning</a></li>
</ul>
</div>
</div>
</div>


<div id="outline-container-orgb819f1c" class="outline-2">
<h2 id="orgb819f1c"><span class="section-number-2">4</span> In Connecting with Others</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-orge21da4a" class="outline-3">
<h3 id="orge21da4a"><span class="section-number-3">4.1</span> Repos on Variational Inference</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li>Repos: <a href="https://github.com/otokonoko8/implicit-variational-inference">Advanced-variational-inference-paper</a></li>
<li>Repos: <a href="https://github.com/otokonoko8/deep-Bayesian-nonparametrics-papers">Deep-Bayesian-nonparametrics-papers</a></li>
</ul>
</div>
</div>



<div id="outline-container-org39042f4" class="outline-3">
<h3 id="org39042f4"><span class="section-number-3">4.2</span> GANs</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li>Literature collection: <a href="https://github.com/hindupuravinash/the-gan-zoo">GAN-zoo</a></li>
<li>Repos: <a href="https://github.com/znxlwm/pytorch-generative-model-collections">Generative adversarial networks</a></li>
</ul>
</div>
</div>

<div id="outline-container-orgf7a348c" class="outline-3">
<h3 id="orgf7a348c"><span class="section-number-3">4.3</span> Optimal Transport (likelihood-free learning)</h3>
<div class="outline-text-3" id="text-4-3">
<ul class="org-ul">
<li>Matthed Thorpe, 2018, <a href="http://www.math.cmu.edu/~mthorpe/OTNotes">Introduction to Optimal Transport</a></li>
<li>Peyre, Cuturi, 2018, Computational Optimal Transport, <a href="https://optimaltransport.github.io/resources/">Codes and slides for OT</a></li>
</ul>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Dong</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>

#+TITLE: A Collection of Literature on Probabilistic Graphical Models
#+LATEX_COMPILER: pdflatex
#+options: toc:2
#+MACRO: color @@html:<font color="$1">$2</font>@@
#+OPTIONS: timestamp:nil

**The collection of literature work on Probabilistic Graphical Models (PGMs). Source file can be found at git repository [[https://github.com/FirstHandScientist/pgm_map][pgm-map]].**
# org-md-export-to-markdown

* Book and Monograph on PGMs

** Books / Monograph:
   
- Kingma and Welling, 2019, [[file:~/Documents/my_eBooks/mLearning/introduction_to_variatinal_autoencoders.pdf][An Introduction to Variational Autoencoders]] 
- Sutton, 2010, [[https://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf][An Introduction to Conditional Random Fields]]
- Wainwright, 2008, [[file:~/Documents/my_eBooks/mLearning/graphical_models_wainwright.pdf][Graphical Models, Exponential Families, and Variational Inference]]
- Koller, 2009, [[file:~/Documents/my_eBooks/mLearning/probabilistic_graphical_models_principles_techniques.pdf][Probabilistic graphical models: principles and techniques]]
- Mark Rowland, 2018, [[https://www.repository.cam.ac.uk/handle/1810/287479][Structure in Machine Learning: Graphical Models and Monte Carlo Methods]]
- Yingzhen Li, 2018, [[https://www.repository.cam.ac.uk/handle/1810/277549][Approximate Inference: New Visions]]
- Adrian Weller, 2014, [[http://mlg.eng.cam.ac.uk/adrian/phd_FINAL.pdf][Methods for Inference in Graphical Models]]

  Ihler, Alexander:

- Lou, Qi, 2018, [[https://escholarship.org/uc/item/7sc0m97f][Anytime Approximate Inference in Graphical Models]]
- Ping, Wei, 2016, [[https://escholarship.org/uc/item/7q90z4b5][Learning and Inference in Latent Variable Graphical Models]]
- Forouzan, Sholeh, 2015, [[https://escholarship.org/uc/item/5n4733cz][Approximate Inference in Graphical Models]]
- Qiang, Liu, 2014, [[https://escholarship.org/uc/item/92p8w3xb][Reasoning and Decisions in Probabilistic Graphical Models - A Unified Framework]]

  Minka:

- Yuan Qi, 2005, [[https://affect.media.mit.edu/pdfs/05.qi-phd.pdf][Extending Expectation Propagation for Graphical Models]]
- Thomas P Minka, 2001, [[https://tminka.github.io/papers/ep/minka-thesis.pdf][A family of algorithms for approximate Bayesian inference]]

** Cached Region

- Angelino, et al 2016, [[https://www.nowpublishers.com/article/Details/MAL-052][Patterns of Scalable Bayesian Inference]]
- Komodakis etc, 2016, [[https://www.nowpublishers.com/article/Details/CGV-066][(Hyper)-Graphs Inference through Convex Relaxations and Move Making Algorithms: Contributions and Applications in Artificial Vision]]
- Bogdan Savchynskyy, 2019, [[file:~/Documents/my_eBooks/mLearning/discrete_graphical_models_an_optimization_perspective.pdf][Discrete Graphical Models -- An Optimization Perspective]]
- Angelino, 2016, [[https://www.nowpublishers.com/article/Details/MAL-052][Patterns of Scalable Bayesian Inference]]  
- Nowozin, 2011, [[http://www.nowozin.net/sebastian/papers/nowozin2011structured-tutorial.pdf][Structured Learning and Prediction in Computer Vision]]

* Inference and Learning of PGMs Papers

** Inference methods and techniques
*** Classical Inference Methods

    Hand-crafted message passing, BP, GBP, Tree-reweighted BP and EP, PowerEP, EC

- Wainwright and Willsky, 2003, [[https://papers.nips.cc/paper/2206-exact-map-estimates-by-hypertree-agreement.pdf][Exact MAP estimates by hypertree agreement]]
- Wainwright et al, 2003, [[http://ssg.mit.edu/group/willsky/publ_pdfs/166_pub_AISTATS.pdf][tree-reweighted belief propagation algorithms and approximated ML esimation by pseudo-moment matching]]
- Generalized BP for marginal distributions, Yedidis, et al, 2005, [[https://www.cs.princeton.edu/courses/archive/spring06/cos598C/papers/YedidaFreemanWeiss2004.pdf][Constructing free energy approximations and Generalized belief propagation algorithms]]
- Tree-structured EP, Minka and Qi, [[https://tminka.github.io/papers/eptree/minka-eptree.pdf][Tree-structured approximations by expectation propagation]]
- Convergence Analysis, Roosta, 2008, [[https://ieeexplore.ieee.org/document/4599175][Convergence Analysis of Reweighted Sum-Product Algorithms]]
- Opper, Winther, 2005, [[http://www.jmlr.org/papers/volume6/opper05a/opper05a.pdf][Expectation Consistent Approximate Inference]]
- Fletcher, 2017, [[https://arxiv.org/abs/1602.07795][Expectation Consistent Approximate Inference: Generalizations and Convergence]]

*** Improvements

- Conditioning and Clamping

  - Eaton and Ghahramani, 2009, [[http://mlg.eng.cam.ac.uk/pub/pdf/EatGha09.pdf][Choosing a Variable to Clamp]]
  - Geier et al, 2015, [[http://auai.org/uai2015/proceedings/papers/158.pdf][Locally Conditioned Belief Propagation]]
  - Weller and Jebara, 2014, [[https://papers.nips.cc/paper/5529-clamping-variables-and-approximate-inference.pdf][Clamping Variables and Approximate Inference]]

- Linear Response. Welling and Teh, [[https://www.ics.uci.edu/~welling/publications/papers/LR2.pdf][Linear Response Algorithms for Approximate Inference in Graphical Models]]

- Combining with Particle/Stochastic Methods

  - Liu et al, 2015, [[https://papers.nips.cc/paper/5695-probabilistic-variational-bounds-for-graphical-models][Probabilistic Variational Bounds for Graphical Models]]
  - Noorshams and Wainwright, 2013, [[https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6373728][stochastic belief propagation: a low-complexity alternative to the sum-product algorithm]]

- Mixture/multi-modal
  - Baque et al, 2017, [[http://openaccess.thecvf.com/content_cvpr_2017/papers/Baque_Multi-Modal_Mean-Fields_via_CVPR_2017_paper.pdf][Multi-Modal Mean-Fields via Cardinality-Based Clamping]]
  - Hao Xiong et al, 2019, [[http://auai.org/uai2019/proceedings/papers/19.pdf][One-Shot Marginal MAP Inference in Markov Random Fields]]


*** Application
- [[https://papers.nips.cc/paper/9532-combining-generative-and-discriminative-models-for-hybrid-inference.pdf][Satorras, 2019, Combining Generative and Discriminative Models for Hybrid Inference]]
- [[https://arxiv.org/pdf/1502.03240.pdf][Zheng, 2019, Conditional Random Fields as Recurrent Neural Networks]]
- [[https://arxiv.org/abs/1210.5644][Krahenbuhl, 2011, Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials]]

** Neural network based methods
*** Deep learning based methods

- Karaletsos, 2016, [[https://arxiv.org/abs/1612.05048][Adversarial Message Passing For Graphical Models]]
- Xiong et al, 2019, [[http://auai.org/uai2019/proceedings/papers/19.pdf][One-Shot Inference in Markov Random Fields]]
- Stoller et al, 2020, [[https://arxiv.org/pdf/1905.12660.pdf][Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators]]

  Learning messages

- Heess et al, [[https://papers.nips.cc/paper/5070-learning-to-pass-expectation-propagation-messages.pdf][Learning to Pass Expectation Propagation Messages]], half-automated message passing, message-level automation
- Yoon et al, 2018, [[https://arxiv.org/abs/1803.07710][Inference in Probabilistic Graphical Models by Graph Neural Networks]]    
- Lin, 2015, [[http://papers.nips.cc/paper/5791-deeply-learning-the-messages-in-message-passing-inference.pdf][Deeply Learning the Messages in Message Passing Inference]]

Graphical Neural Networks

- [[https://arxiv.org/abs/1905.06214][GMNN: Graph Markov Neural Networks]], semi-supervised learning, EM is used for training.
- More generalized computation power: [[https://github.com/deepmind/graph_nets][Graph Net Library]], A graph network takes a graph as input and returns a graph as output.
- Related, [[https://github.com/dmlc/dgl][Deep Graph Library]], for deep learning on graphs
- Scarselli et al, 2009, [[https://persagen.com/files/misc/scarselli2009graph.pdf][The graph neural network model]]
- Satorras and Welling, 2020, [[https://arxiv.org/abs/2003.01998][Neural Enhanced Belief Propagation on Factor Graphs]]    

*** Variational methods   
    
- NIPS tutorial 2016, [[https://media.nips.cc/Conferences/2016/Slides/6199-Slides.pdf][Variational Inference]]
- Kingma and Welling, 2014, Autoencoder: [[https://arxiv.org/abs/1312.6114][Auto-Encoding Variational Bayes]]  
- Kuleshov and Ermon, 2017, NVIL: [[https://arxiv.org/abs/1711.02679][Neural Variational Inference and Learning in Undirected Graphical Models]]
- Li, etc, 2020, AdVIL: [[https://arxiv.org/abs/1901.08400][To Relieve Your Headache of Training an MRF, Take AdVIL]]
- Lazaro-Gredilla, 2019 (Vicarious AI), [[https://arxiv.org/abs/1912.02893][Learning undirected models via query training]]
- Sobolev and Vetrov, 2019, (Section 3 gives interesting discussion on literature works) [[http://papers.nips.cc/paper/8350-importance-weighted-hierarchical-variational-inference][Importance Weighted Hierarchical Variational Inference]]
- Kingma, et al, 2016, [[https://papers.nips.cc/paper/6581-improved-variational-inference-with-inverse-autoregressive-flow][Improved Variational Inference with Inverse Autoregressive Flow]]  
- Rezende, Mohamed, 2015, [[https://arxiv.org/abs/1505.05770][Variational Inference with Normalizing Flows]]

*** Neural density function estimation
- Chen et al, 2018, ODE: [[https://papers.nips.cc/paper/7892-neural-ordinary-differential-equations][Neural Ordinary Differential Equations]]
- Kingma, Dhariwal, 2018, [[https://arxiv.org/abs/1807.03039][Glow: Generative Flow with Invertible 1x1 Convolutions]]  
- Dinh, Sohl-Dickstein, Bengio, 2017, [[https://arxiv.org/pdf/1605.08803.pdf][Density Estimation using Real NVP]]
- Dinh, Krueger, Bengio, 2014, [[https://arxiv.org/abs/1410.8516][NICE: Non-linear independent component estimation]]  
- Inverse autoregreeeive flow as in previous subsection.
    
** Learning of Graphical Models

*** Parameter Learning

    Learning graphical model parameters by approximate inference

- Domke, 2013, [[https://ieeexplore.ieee.org/abstract/document/6420841][Learning Graphical Model Parameters with Approximate Marginal Inference]]
- Tang, 2015, [[https://arxiv.org/abs/1503.01228][Bethe Learning of Conditional Random Fields via MAP Decoding]]
- You Lu, 2019, [[https://www.aaai.org/ojs/index.php/AAAI/article/view/4357][Block Belief Propagation for Parameter Learning in Markov Random Fields]]
- Hazan, 2016, [[http://www.jmlr.org/papers/v17/13-260.html][Blending Learning and Inference in Conditional Random Fields]]

Learning of MRF with neural networks

- Wiseman and Kim, 2019, [[https://papers.nips.cc/paper/9687-amortized-bethe-free-energy-minimization-for-learning-mrfs.pdf][Amortized Bethe Free Energy Minimization for Learning MRFs]]
- Kuleshov and Ermon, 2017, [[https://arxiv.org/abs/1711.02679][Neural Variational Inference and Learning in Undirected Graphical Models]]

Learning of Directed Graphs

- Chongxuan Li, 2020, [[https://arxiv.org/abs/1901.08400][To Relieve Your Headache of Training an MRF, Take AdVIL]]
- Mnih and Gregor, 2014, [[https://arxiv.org/abs/1402.0030][Neural Variational Inference and Learning in Belief Networks]]
- NIPS tutorial 2016, [[https://media.nips.cc/Conferences/2016/Slides/6199-Slides.pdf][Variational Inference]]


* PGM and Decision-making in Dynamic Systems

+ Sutton, Barto, 2018, [[https://github.com/FirstHandScientist/Reinforcement-Learning-2nd-Edition-by-Sutton-Exercise-Solutions][Reinforcement learning (2ed edition)]]

+ Martin L. Puterman, 2014, Markov Decision Processes: Discrete Stochastic Dynamic Programming

+ Francois-Lavet, et al 2018, [[https://arxiv.org/abs/1811.12560][An Introduction to Deep Reinforcement Learning]] 

+ Bubeck, Cesa-Bianchi, 2012, [[https://www.microsoft.com/en-us/research/wp-content/uploads/2017/01/SurveyBCB12.pdf][Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems]] 

+ Ziebart, 2010, [[https://www.cs.cmu.edu/~bziebart/publications/thesis-bziebart.pdf][Modeling Purposeful Adaptive Behavior with the Principle of Maximum Causal Entropy]]

+ Levin, 2018, [[https://arxiv.org/abs/1805.00909][Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review]]

+ Haarnoja, et al 2017, [[https://arxiv.org/pdf/1702.08165.pdf][Reinforcement Learning with Deep Energy-Based Policies]]
  
+ Szepesvari, 2009, [[https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs-lecture.pdf][Algorithms for Reinforcement Learning]]


** Courses

- [[https://www.davidsilver.uk/teaching/][Reinforcement Learning (UCL)]]
- [[http://rail.eecs.berkeley.edu/deeprlcourse/][Deep Reinforcement Learning (CS285)]]
- [[https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs][Advanced Deep Learning & Reinforcement Learning]]

    
* In Connecting with Others

** Repos on Variational Inference
+ Repos: [[https://github.com/otokonoko8/implicit-variational-inference][Advanced-variational-inference-paper]]
+ Repos: [[https://github.com/otokonoko8/deep-Bayesian-nonparametrics-papers][Deep-Bayesian-nonparametrics-papers]] 


  
** GANs

+ Literature collection: [[https://github.com/hindupuravinash/the-gan-zoo][GAN-zoo]]
+ Repos: [[https://github.com/znxlwm/pytorch-generative-model-collections][Generative adversarial networks]]


# ** Discrete GAN or RBM or Autoencoder

** Optimal Transport (likelihood-free learning)

- Matthed Thorpe, 2018, [[http://www.math.cmu.edu/~mthorpe/OTNotes][Introduction to Optimal Transport]]
- Peyre, Cuturi, 2018, Computational Optimal Transport, [[https://optimaltransport.github.io/resources/][Codes and slides for OT]]



